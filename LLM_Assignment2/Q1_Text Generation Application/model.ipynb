{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing PyTorch, a deep learning framework\n",
    "import torch\n",
    "\n",
    "# Importing necessary components from the Hugging Face Transformers library\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,  # Model class for causal language modeling\n",
    "    AutoTokenizer,         # Tokenizer class for auto-loading tokenizers\n",
    "    GPT2Tokenizer,         # Tokenizer specific to GPT-2\n",
    "    GPT2LMHeadModel,       # GPT-2 model class with a language modeling head\n",
    "    BloomTokenizerFast,    # Tokenizer specific to Bloom model\n",
    "    BloomForCausalLM       # Bloom model class for causal language modeling\n",
    ")\n",
    "\n",
    "# Importing tools for text vectorization and similarity measurement\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # TF-IDF vectorizer for text feature extraction\n",
    "from sklearn.metrics.pairwise import cosine_similarity  # Function to compute cosine similarity between vectors\n",
    "\n",
    "# Importing text statistics and analysis tools\n",
    "from textstat import flesch_reading_ease  # Function to calculate the Flesch Reading Ease score\n",
    "from textblob import TextBlob  # Library for text processing and sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate text from a model\n",
    "def generate_text(model_name, prompt):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_length=500,\n",
    "        num_return_sequences=1,\n",
    "        repetition_penalty=1.2,\n",
    "        temperature=0.7,\n",
    "        top_k=50,\n",
    "        top_p=0.9\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `evaluate_fluency_with_perplexity` Function\n",
    "\n",
    "This function evaluates the fluency of a given text using the perplexity metric. Perplexity is a measure of how well a language model predicts a sample and is often used to assess model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fluency_with_perplexity(model_name, text):\n",
    "    if 'gpt2' in model_name.lower():\n",
    "        # Load the GPT-2 tokenizer and model\n",
    "        tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "        model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "    elif 'bloom' in model_name.lower():\n",
    "        # Load the Bloom tokenizer and model\n",
    "        tokenizer = BloomTokenizerFast.from_pretrained(model_name)\n",
    "        model = BloomForCausalLM.from_pretrained(model_name)\n",
    "    else:\n",
    "        raise ValueError(f\"Model {model_name} not supported for perplexity evaluation.\")\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "        loss = outputs.loss\n",
    "        perplexity = torch.exp(loss).item()\n",
    "\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `analyze_tone` Function\n",
    "\n",
    "This function analyzes the tone of a given text using sentiment analysis provided by the TextBlob library. The tone is classified into three categories: Positive, Negative, or Neutral based on the sentiment polarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze tone using TextBlob\n",
    "def analyze_tone(text):\n",
    "    analysis = TextBlob(text)\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return \"Positive\"\n",
    "    elif analysis.sentiment.polarity < 0:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `evaluate_relevance`\n",
    "\n",
    "Evaluates the relevance of a generated text with respect to a given prompt using TF-IDF and cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate relevance\n",
    "def evaluate_relevance(prompt, generated_text):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectors = vectorizer.fit_transform([prompt, generated_text])\n",
    "    similarity = cosine_similarity(vectors[0:1], vectors[1:2])\n",
    "    return similarity[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `calculate_lexical_diversity`\n",
    "\n",
    "Calculates the lexical diversity of a text, which is the ratio of unique words to the total number of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate lexical diversity\n",
    "def calculate_lexical_diversity(text):\n",
    "    tokens = text.split()\n",
    "    types = set(tokens)\n",
    "    return len(types) / len(tokens) if tokens else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `evaluate_length`\n",
    "\n",
    "Checks if the length of the text (in terms of word count) falls within a specified range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check text length\n",
    "def evaluate_length(text, min_length=50, max_length=500):\n",
    "    length = len(text.split())\n",
    "    return min_length <= length <= max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check originality (Placeholder function)\n",
    "def check_originality(text):\n",
    "    return \"Originality placeholder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fact-checking (Placeholder function)\n",
    "def check_facts(text):\n",
    "    return \"Fact-checking placeholder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect bias (Placeholder function)\n",
    "def detect_bias(text):\n",
    "    return \"Bias detection placeholder\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `evaluate_topic_coverage`\n",
    "\n",
    "Evaluates how well the text covers the provided keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate topic coverage\n",
    "def evaluate_topic_coverage(text, keywords):\n",
    "    covered_keywords = [kw for kw in keywords if kw in text]\n",
    "    return len(covered_keywords) / len(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `evaluate_readability`\n",
    "\n",
    "Evaluates the readability of the text using the Flesch Reading Ease score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate readability\n",
    "def evaluate_readability(text):\n",
    "    return flesch_reading_ease(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_summary(summary_text):\n",
    "    # Count the number of words in the text\n",
    "    word_count = len(summary_text.split())\n",
    "\n",
    "    # Display the text line by line\n",
    "    for line in summary_text.split('. '):\n",
    "        print(line.strip())\n",
    "\n",
    "    print(f\"\\nNumber of words in the Text: {word_count}\")\n",
    "\n",
    "def evaluate_models(models, prompt, topic_keywords, model_names):\n",
    "    results = {}\n",
    "    for model_name in models:\n",
    "        generated_text = generate_text(model_name, prompt)\n",
    "        \n",
    "        # Format the generated text\n",
    "        formatted_text = \"\\n\".join(generated_text.split(\"\\n\"))\n",
    "        \n",
    "        # Perform evaluations\n",
    "        fluency_score = evaluate_fluency_with_perplexity(model_name, formatted_text)\n",
    "        relevance_score = evaluate_relevance(prompt, formatted_text)\n",
    "        diversity_score = calculate_lexical_diversity(formatted_text)\n",
    "        length_ok = evaluate_length(formatted_text)\n",
    "        originality_check = check_originality(formatted_text)\n",
    "        fact_check = check_facts(formatted_text)\n",
    "        bias_check = detect_bias(formatted_text)\n",
    "        topic_coverage = evaluate_topic_coverage(formatted_text, topic_keywords)\n",
    "        readability_score = evaluate_readability(formatted_text)\n",
    "        tone_analysis = analyze_tone(formatted_text)\n",
    "        \n",
    "        # Store results\n",
    "        results[model_name] = {\n",
    "            \"text\": formatted_text,\n",
    "            \"fluency\": fluency_score,\n",
    "            \"relevance\": relevance_score,\n",
    "            \"diversity\": diversity_score,\n",
    "            \"length_ok\": length_ok,\n",
    "            \"originality\": originality_check,\n",
    "            \"fact_check\": fact_check,\n",
    "            \"bias\": bias_check,\n",
    "            \"topic_coverage\": topic_coverage,\n",
    "            \"readability\": readability_score,\n",
    "            \"tone\": tone_analysis\n",
    "        }\n",
    "        \n",
    "        # Print the results\n",
    "        print(f\"Model: {model_name}\\n\")\n",
    "        # Display the summary\n",
    "        display_summary(formatted_text)\n",
    "        print(f\"\\nFluency Score: {fluency_score}\")\n",
    "        print(f\"Relevance Score: {relevance_score}\")\n",
    "        print(f\"Diversity Score: {diversity_score}\")\n",
    "        print(f\"Length OK: {length_ok}\")\n",
    "        print(f\"Originality Check: {originality_check}\")\n",
    "        print(f\"Fact Check: {fact_check}\")\n",
    "        print(f\"Bias Check: {bias_check}\")\n",
    "        print(f\"Topic Coverage: {topic_coverage}\")\n",
    "        print(f\"Readability Score: {readability_score}\")\n",
    "        print(f\"Tone Analysis: {tone_analysis}\")\n",
    "        print(\"\\n\" + \"-\" * 50 + \"\\n\")\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: gpt2\n",
      "\n",
      "Discuss the role of education in achieving Sustainable Development Goal 4 (Quality Education).\n",
      "The following is a list of key issues that need to be addressed before we can achieve our goal\n",
      "The first issue, which needs addressing right now and will become more important as time goes on, involves ensuring schools are equipped with appropriate training for students who have not yet completed their degree requirements or if they do so would require further study at an accredited university such Asperger's Institute where there may also be additional resources available including courses from other universities but this should only take place once you've been certified by your school authorities within three years after graduation into high quality teaching positions under guidance provided through local government departments like Schools Councils etc.\n",
      "This means it must include all aspects of learning skills needed during these four-year periods - reading comprehension; writing/writing ability; problem solving abilities; social interaction capabilities; language development capacity; communication capability; mathematics proficiency; English speaking competence; maths knowledge level 2+2 = 3rd grade\n",
      "\n",
      " (1) In order ensure pupils receive adequate support when required: • Ensure teachers provide sufficient information about what has happened since last year – whether any specific events occurred prior to those incidents being reported online via email messages sent out over phone calls between staff members• Provide feedback regarding how well each teacher was doing throughout his work week while he worked day hours working alone without supervision because some were unable access classroom materials due concerns raised against them having too much control Overcome difficulties relating directly related to student behaviour outside class activities If possible make sure every pupil receives proper instruction immediately upon arrival home From my experience I am very aware many parents feel uncomfortable dealing with children coming back late one night whilst sitting down next door looking bored despite knowing exactly why things went wrong\n",
      "It seems often times kids come up early thinking 'I'm going away', even though most people don't realise just then something really bad had gone horribly awry!!! We know sometimes young boys get upset around homework assignments especially given recent changes made towards grading systems   And although no matter whom comes across problems here usually isn´t always someone else involved! So please remember everyone gets along fine!\n",
      "\n",
      "Number of words in the Text: 383\n",
      "\n",
      "Fluency Score: 35.72355270385742\n",
      "Relevance Score: 0.20629047352864277\n",
      "Diversity Score: 0.9817232375979112\n",
      "Length OK: True\n",
      "Originality Check: Originality placeholder\n",
      "Fact Check: Fact-checking placeholder\n",
      "Bias Check: Bias detection placeholder\n",
      "Topic Coverage: 0.5\n",
      "Readability Score: 8.1\n",
      "Tone Analysis: Positive\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `past_key_values` as a tuple is deprecated and will be removed in v4.45. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: bigscience/bloom-560m\n",
      "\n",
      "Discuss the role of education in achieving Sustainable Development Goal 4 (Quality Education).\n",
      "\n",
      "Number of words in the Text: 13\n",
      "\n",
      "Fluency Score: 31.918127059936523\n",
      "Relevance Score: 1.0\n",
      "Diversity Score: 1.0\n",
      "Length OK: False\n",
      "Originality Check: Originality placeholder\n",
      "Fact Check: Fact-checking placeholder\n",
      "Bias Check: Bias detection placeholder\n",
      "Topic Coverage: 0.5\n",
      "Readability Score: 7.52\n",
      "Tone Analysis: Neutral\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define your prompt and topic keywords we want to evaluate\n",
    "model_names = ['gpt2', 'bigscience/bloom-560m']\n",
    "models = {name: name for name in model_names} \n",
    "prompt = \"Discuss the role of education in achieving Sustainable Development Goal 4 (Quality Education).\"\n",
    "topic_keywords = [\"Quality Education\", \"Education\", \"SDG4\", \"Skill Development\"]\n",
    "\n",
    "# Evaluation\n",
    "results = evaluate_models(models, prompt, topic_keywords, model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: gpt2\n",
      "\n",
      "How can renewable energy contribute to the success of Sustainable Development Goal 7 (Affordable and Clean Energy)?\n",
      "The following is a list of some key points that are important for sustainable development\n",
      "The goal states: \"We must ensure all people have access to clean, affordable electricity.\" This means we need more power from renewables in order not only meet our needs but also provide an alternative source or fuel which will be cheaper than fossil fuels such as coal-fired plants\"\n",
      "In other words it's about getting enough solar panels on your roof so you don't burn too much carbon dioxide into them! It should help us get rid out of greenhouse gases by reducing emissions through cleaner sources like wind turbines – this would reduce CO2 levels at home while increasing efficiency with less pollution coming back down onto society via increased use of natural gas instead…\n",
      "\n",
      "Number of words in the Text: 147\n",
      "\n",
      "Fluency Score: 19.63784408569336\n",
      "Relevance Score: 0.3895494956085688\n",
      "Diversity Score: 0.9659863945578231\n",
      "Length OK: True\n",
      "Originality Check: Originality placeholder\n",
      "Fact Check: Fact-checking placeholder\n",
      "Bias Check: Bias detection placeholder\n",
      "Topic Coverage: 0.3333333333333333\n",
      "Readability Score: 55.27\n",
      "Tone Analysis: Positive\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Model: bigscience/bloom-560m\n",
      "\n",
      "How can renewable energy contribute to the success of Sustainable Development Goal 7 (Affordable and Clean Energy)? The answer is that it will be a key driver for sustainable development\n",
      "In this paper, we present an analysis on how solar power contributes towards achieving these goals.\n",
      "The rest part describes our methodology in detail: first some background information about sustainability are presented before presenting results from different studies related with climate change mitigation strategies; then two case study examples based upon wind farms' performance evaluation by using data collected during field experiments conducted at three locations around Europe are:\n",
      "• Germany • Austria\n",
      "\n",
      "Background Information About Sustainability Researches Related With Climate Change Mitigation Strategies\n",
      "(1) Environmental impact assessment -Environmental impacts associated with: 1)\n",
      "Sustainable production systems 2).\n",
      "Energy efficiency 3)\n",
      "Renewables 4).\n",
      "\n",
      "Greenhouse gas emissions 5)\n",
      "\n",
      "Economic benefits 6) .\n",
      "Social welfare [7] .\n",
      "In order not only reduce environmental damage but also increase economic growth as well [8] , several research projects have been carried out since 1990 [9]\n",
      "These include many works focusing on:  Eco-efficiency measures [10] [11] [12] [13] [14] [15] [16] [17] [18] [19] [20] [21] [22] [23] [24] [25] [26] [27] [28] [29] [30] [31] [32] [33] [34] [35] [36] [37] ; \n",
      "Research Methodology Used For Analysis Of Wind Farm Performance Evaluation Data Collection During Field Experiments At Three Locations Around European Countries\n",
      "\n",
      "(2) \n",
      "Results And Discussion From Different Studies Based Upon Wind Furnace's Performances Evaluation By Using Datasets Collected On Areas Nearly Located To Their Originals Location.\n",
      "(3) (4)\n",
      "(5)\n",
      "Figure 1: Flowchart showing steps involved when analyzing performances evaluations performed within one year period\n",
      "(6) , which was done after applying various methods such as: regression models, (7), statistical tests or other techniques like ANOVA tests; finally another method used hereafter is: Principal Component Analyses\n",
      "Conclusions & Future Works: Conclusion/Implications /Future Works\n",
      "\n",
      "Number of words in the Text: 312\n",
      "\n",
      "Fluency Score: 14.395912170410156\n",
      "Relevance Score: 0.24038152349900488\n",
      "Diversity Score: 0.967948717948718\n",
      "Length OK: True\n",
      "Originality Check: Originality placeholder\n",
      "Fact Check: Fact-checking placeholder\n",
      "Bias Check: Bias detection placeholder\n",
      "Topic Coverage: 0.4444444444444444\n",
      "Readability Score: 22.55\n",
      "Tone Analysis: Positive\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"How can renewable energy contribute to the success of Sustainable Development Goal 7 (Affordable and Clean Energy)?\"\n",
    "topic_keywords = [\"Affordable Energy\", \"Clean\", \"Renewable\", \"Energy\", \"Electricity\",\"Solar\", \"Affordable\", \"Emission\", \"Gas\"]\n",
    "results = evaluate_models(models, prompt, topic_keywords, model_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
