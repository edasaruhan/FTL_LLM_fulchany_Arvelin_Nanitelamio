# SDG Text Generation Application

## Table of Contents

1. [Overview](#overview)
2. [Features](#features)
3. [Models Used](#models-used)
   - [GPT-2](#gpt-2)
   - [Bloom](#bloom)
4. [Installation](#installation)
5. [Usage](#usage)
6. [Code Explanation](#code-explanation)
   - [model.ipynb](#modelipynb)
   - [app.py](#apppy)
   - [requirements.txt](#requirements-txt)
8. [Evaluation](#evaluation)
   - [Evaluation Metrics](#evaluation-metrics)
   - [Sample Results](#sample-results)
9. [User Interface](#user-interface)
10. [Conclusion](#conclusion)
11. [Acknowledgments](#acknowledgments)

## Overview

The **SDG Text Generation Application** is designed to generate relevant and coherent text based on user-provided prompts related to Sustainable Development Goals (SDGs). This application leverages state-of-the-art generative AI models to assist users in exploring and understanding various SDGs through generated text.

## Features

- **Interactive Text Generation**: Users can input prompts related to SDGs and receive AI-generated text.
- **Model Comparison**: Evaluates and compares the performance of different generative models.
- **User-Friendly Interface**: Built with Streamlit for an intuitive and seamless user experience.
- **Performance Metrics**: Detailed evaluation of models based on fluency, relevance, diversity, readability, tone, and topic coverage.

## Models Used

### GPT-2

**GPT-2** (Generative Pre-trained Transformer 2) by OpenAI is known for its impressive text generation capabilities. It was chosen for the final implementation due to:

- **High-Quality Text Generation**: Produces coherent and contextually relevant text.
- **Flexibility and Versatility**: Handles a wide range of prompts effectively.
- **Ease of Integration**: Well-supported by Streamlit, making it straightforward to integrate.

### Bloom

**Bloom** is another advanced generative model that was evaluated as part of the project. Despite its strengths, it was not selected for the final version due to:

- **Integration Complexity**: More challenging to set up and integrate compared to GPT-2.
- **Performance Results**: While capable, GPT-2 provided more consistent results for the specific tasks.

## Installation

To set up the SDG Text Generation Application:

1. **Clone the Repository**:

   ```bash
   git clone https://github.com/edasaruhan/FTL_LLM_fulchany_Arvelin_Nanitelamio.git
   ```
   
2. **Run the Application**:
   ```bash
   streamlit run app.py
   ```

## Usage

1. **Launch the Application**: Start the Streamlit app using the command above.
2. **Enter a Prompt**: Input a text prompt related to SDGs in the provided field.
3. **Generate Text**: Click the button to generate and view text based on the prompt.

## Code Explanation

### model.ipynb

The `model.ipynb` notebook is used for evaluating the performance of various generative models. It provides a detailed analysis of text generated by different models. This notebook is crucial for understanding how each model performs in terms of fluency, relevance, diversity, and other metrics.

**Key Components and Workflow:**

1. **Model Import and Setup**:
   - Imports necessary libraries and models.
   - Sets up the environment for text generation and evaluation.

2. **Text Generation**:
   - Defines functions to generate text using different models.
   - Uses these functions to generate text based on provided prompts.

3. **Evaluation Metrics**:
   - **Fluency**: Uses perplexity to measure how well a model predicts text.
   - **Relevance**: Uses TF-IDF and cosine similarity to assess text relevance.
   - **Diversity**: Calculates lexical diversity based on unique word usage.
   - **Readability**: Uses Flesch Reading Ease score to evaluate text readability.
   - **Tone**: Analyzes sentiment to determine the tone of the text.

4. **Evaluation Results**:
   - Prints and stores the results for each model, including generated text and evaluation metrics.

**How to Use `model.ipynb`:**

1. **Open the Notebook**: Use Jupyter Notebook or any compatible environment.
2. **Run the Cells**: Execute each cell to set up the environment, generate text, and perform evaluations.
3. **Analyze Results**: Review the output to understand the performance of each model based on various metrics.

### app.py

The `app.py` file is the core of the Streamlit application. It handles user interaction and text generation. Key functionalities include:

- **Prompt Input**: Collects user input for text generation.
- **Model Loading**: Loads the selected model (GPT-2 or Bloom) for generating text.
- **Text Generation**: Uses the model to generate text based on the input prompt.
- **Display Results**: Shows the generated text and related metrics to the user.

### requirements.txt

Lists all necessary Python packages for the application, including:

- `streamlit` for the web interface.
- `transformers` for the AI models.
- `torch` for model processing.

## Evaluation

### Evaluation Metrics

The models were evaluated based on:

- **Fluency**: Assessed by perplexity, indicating how well the model predicts the text.
- **Relevance**: Measured using TF-IDF and cosine similarity.
- **Diversity**: Ratio of unique words to total words.
- **Readability**: Flesch Reading Ease score.
- **Tone**: Sentiment analysis for tone classification.
- **Topic Coverage**: Analysis based on the inclusion of relevant keywords.

### Sample Results

**GPT-2:**

- **Generated Text**: [Sample text here]
- **Fluency Score**: 19.64
- **Relevance Score**: 0.39
- **Diversity Score**: 0.97
- **Length OK**: True
- **Readability Score**: 55.27
- **Tone Analysis**: Positive

**Bloom:**

- **Generated Text**: [Sample text here]
- **Fluency Score**: 14.40
- **Relevance Score**: 0.24
- **Diversity Score**: 0.97
- **Length OK**: True
- **Readability Score**: 22.55
- **Tone Analysis**: Positive

## User Interface 
<img width="587" alt="Q1_1" src="https://github.com/user-attachments/assets/1fe41d69-1f32-4040-bd4c-2e95e1abc9dd">
<img width="459" alt="Q1_2" src="https://github.com/user-attachments/assets/c3fe00d9-6fb4-45a4-a484-ed3790453384">
<img width="380" alt="Q1_3" src="https://github.com/user-attachments/assets/eec6f8b8-08c2-4cd8-a190-3933b17e3421">

## Conclusion

GPT-2 was selected for the final implementation due to its superior integration ease, high-quality text generation, and consistent performance across various metrics. Bloom, while capable, was not chosen due to its integration complexity and less consistent results.

## Acknowledgments

- **Frontier tech leaders** for the Bootcamp and Project Idea
- **OpenAI** for GPT-2.
- **BigScience** for Bloom.
- **Hugging Face** for the Transformers library.
